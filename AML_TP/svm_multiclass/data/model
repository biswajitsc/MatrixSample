SVM-multiclass Version V2.20
2 # number of classes
144 # number of base features
0 # loss function
0 # kernel type
3 # kernel parameter -d 
1 # kernel parameter -g 
1 # kernel parameter -s 
1 # kernel parameter -r 
empty# kernel parameter -u 
289 # highest feature index 
25 # number of training documents 
2 # number of support vectors plus 1 
0 # threshold b, each following line is a SV (starting with alpha*y)
1 qid:0 1:0.0079879388 2:0.028463604 3:0.13939655 4:0.09470813 5:-0.23190661 6:-0.36508974 7:0.29177719 8:0.31962696 9:0.33689302 10:0.35115421 11:-1.0852116 12:0.096626222 13:-0.71036917 14:-0.27491415 15:-0.3830525 16:0.71760768 17:-0.20475443 18:0.51021916 19:-0.071563452 20:-0.20979376 21:0.0032268707 22:-0.13107267 23:0.36123255 24:-0.20579436 25:-0.27875677 26:-0.23910002 27:0.14649616 28:0.014271435 29:0.079153053 30:0.80307555 31:0.32932141 32:0.012127897 33:-0.16591606 34:0.045870319 35:-0.40023276 36:0.33237547 37:-0.11937714 38:0.48368123 39:-0.018826224 40:-0.46747905 41:-0.17069714 42:-0.14365979 43:0.1020191 44:0.078564487 45:0.16877037 46:-0.00750631 47:-0.023697581 48:-0.035635296 49:-0.44721264 50:-0.26905063 51:0.0028833456 52:-0.12249348 53:0.088595614 54:0.086200975 55:-0.30037105 56:-0.00013543405 57:-0.33044806 58:-0.31466082 59:0.27196485 60:0.13113853 61:-0.30017522 62:0.0031271467 63:0.11164311 64:0.29185849 65:0.036734365 66:0.28470907 67:0.097061493 68:-0.009182659 69:-0.1607601 70:0.20244406 71:-0.086099036 72:-0.19062062 73:-0.18333067 74:-0.20103903 75:-0.13258921 76:-0.038759608 77:-0.091010652 78:0.16173154 79:0.060620423 80:0.22470887 81:0.15948622 82:-0.037417606 83:-0.17323184 84:-0.06238262 85:0.23456421 86:0.23731327 87:0.060735032 88:-0.037423335 89:-0.037693169 90:0.032825597 91:0.035304755 92:0.31308925 93:0.0043544881 94:0.095966257 95:-0.043014377 96:0.0023738986 97:-0.2382388 98:0.19543827 99:-0.041272223 100:-0.013304662 101:0.080913693 102:-0.052423317 103:-0.047535297 104:-0.018362455 105:0.13699694 106:-0.075001486 107:0.11298968 108:0.0082851835 109:0.1270268 110:-0.052405905 111:0.054666169 112:0.038314138 113:-0.05241612 114:-0.12777284 115:-0.087468021 116:0.021898191 117:0.01376189 118:0.088108927 119:0.057648152 120:0.021452123 121:0.0078597423 122:-0.017041495 123:-0.013501467 124:0.010093204 125:0.04685235 126:0.028282473 127:-0.068375975 128:0.013934004 129:0.01835431 130:0.0034267546 131:0.011558355 132:-0.0047959737 145:-0.0079879388 146:-0.028463604 147:-0.13939655 148:-0.09470813 149:0.23190661 150:0.36508974 151:-0.29177719 152:-0.31962696 153:-0.33689302 154:-0.35115421 155:1.0852116 156:-0.096626222 157:0.71036917 158:0.27491415 159:0.3830525 160:-0.71760768 161:0.20475443 162:-0.51021916 163:0.071563452 164:0.20979376 165:-0.0032268707 166:0.13107267 167:-0.36123255 168:0.20579436 169:0.27875677 170:0.23910002 171:-0.14649616 172:-0.014271435 173:-0.079153053 174:-0.80307555 175:-0.32932141 176:-0.012127897 177:0.16591606 178:-0.045870319 179:0.40023276 180:-0.33237547 181:0.11937714 182:-0.48368123 183:0.018826224 184:0.46747905 185:0.17069714 186:0.14365979 187:-0.1020191 188:-0.078564487 189:-0.16877037 190:0.00750631 191:0.023697581 192:0.035635296 193:0.44721264 194:0.26905063 195:-0.0028833456 196:0.12249348 197:-0.088595614 198:-0.086200975 199:0.30037105 200:0.00013543405 201:0.33044806 202:0.31466082 203:-0.27196485 204:-0.13113853 205:0.30017522 206:-0.0031271467 207:-0.11164311 208:-0.29185849 209:-0.036734365 210:-0.28470907 211:-0.097061493 212:0.009182659 213:0.1607601 214:-0.20244406 215:0.086099036 216:0.19062062 217:0.18333067 218:0.20103903 219:0.13258921 220:0.038759608 221:0.091010652 222:-0.16173154 223:-0.060620423 224:-0.22470887 225:-0.15948622 226:0.037417606 227:0.17323184 228:0.06238262 229:-0.23456421 230:-0.23731327 231:-0.060735032 232:0.037423335 233:0.037693169 234:-0.032825597 235:-0.035304755 236:-0.31308925 237:-0.0043544881 238:-0.095966257 239:0.043014377 240:-0.0023738986 241:0.2382388 242:-0.19543827 243:0.041272223 244:0.013304662 245:-0.080913693 246:0.052423317 247:0.047535297 248:0.018362455 249:-0.13699694 250:0.075001486 251:-0.11298968 252:-0.0082851835 253:-0.1270268 254:0.052405905 255:-0.054666169 256:-0.038314138 257:0.05241612 258:0.12777284 259:0.087468021 260:-0.021898191 261:-0.01376189 262:-0.088108927 263:-0.057648152 264:-0.021452123 265:-0.0078597423 266:0.017041495 267:0.013501467 268:-0.010093204 269:-0.04685235 270:-0.028282473 271:0.068375975 272:-0.013934004 273:-0.01835431 274:-0.0034267546 275:-0.011558355 276:0.0047959737 #
